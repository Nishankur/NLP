{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4J-m4pQvao1u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yOOYR6jesRLK"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-K3m0dQbr357"
   },
   "source": [
    "# **Extraction and Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BoURSAMIqcbK"
   },
   "outputs": [],
   "source": [
    "url = \"http://archives.textfiles.com/stories.zip\"\n",
    "extract_dir = \"text_files\"\n",
    "\n",
    "zip_path, _ = urllib.request.urlretrieve(url)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "    f.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quUJI06xtCo9",
    "outputId": "d14804a8-4109-4b7e-e204-ffe1c075a560"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100west.txt',\n",
       " '13chil.txt',\n",
       " '14.lws',\n",
       " '16.lws',\n",
       " '17.lws',\n",
       " '18.lws',\n",
       " '19.lws',\n",
       " '20.lws',\n",
       " '3gables.txt',\n",
       " '3lpigs.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),extract_dir)\n",
    "extracted_files_path = os.path.join(path,'stories')\n",
    "os.listdir(extracted_files_path)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hlgwY4FtpGG",
    "outputId": "3e6f7e5a-0693-4b91-f045-5945d2cbc7ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\100west.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\13chil.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\3gables.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\3lpigs.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\3student.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\3wishes.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\4moons.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\5orange.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\6ablemen.txt',\n",
       " 'C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\6napolen.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files = glob.glob(extracted_files_path + '/*.txt')\n",
    "text_files[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "x84qGkb_8SIw"
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    file_ = open(r'{}'.format(path),\"r\",encoding='utf8', errors='ignore')\n",
    "    text = file_.read()\n",
    "    file_.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "DI_8yp6aI-S0",
    "outputId": "b7c0d3e4-3f49-4acc-815e-6f3a92691f6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                          B O O K   \\'E M\\n\\n                      Volume one     Number 1\\n                                   \\n    Author: Caroline Kent   e-mail: caro@freenet.fsu.edu    \\n\\n\\n   Copyright (c) 1995 by Caroline Kent.  All Rights Reserved.\\n\\n\\n     \"Hi everyone!  Welcome to the premiere issue of \"Book \\'Em,\"\\nan informal e-zine that is written especially for bookstore\\nlovers.  I have been a bookseller for almost four years and I\\'d\\nlike to share some of my thoughts and experiences with you.\"\\n     (I glance at my watch) \\n     \"If I don\\'t hurry, I\\'m going to be late for work.  Why don\\'t\\nyou come along with me to \"Book \\'Em\" and we\\'ll chat some more?\"  \\n     (I drive to the store with a caravan of cars following me. \\nUpon arriving, I lead everyone through the front door. A large\\nstack of boxes is being unloaded from a truck) \\n     \"A lot of you probably think that a bookstore is a quiet,\\ndull place where the most exciting event of the year is the\\ndelivery of the newest release by John Grisham . . .\"\\n     (I slit open one of the boxes and peek inside)\\n      \"Oh, it\\'s here!  `The Rainmaker\\'  is here!\"  \\n     (I dance around the store and do cartwheels in the aisles.\\nBreathlessly, I return to the box, take out a copy, and start to\\nread.  Someone clears their throat and I look up)\\n     \"Oh, forgive me  . . .  I just had to read the first \\npage . . . for selling purposes, you know.\" \\n     (I take the book and place it in the front window and return\\nto my guests) \\n     \"Now, what were we discussing . . . oh yes, excitement in a\\nbookstore . . .\"\\n     (I am interrupted by a crash from the spot where I had just\\nplaced the book)\\n     \"Uh, excuse me for just a moment . . .\"   \\n     (I go over to the window where two old ladies are in a\\ntug-of-war over \"The Rainmaker\") \\n     \"May I help you?\" I ask, trying in vain to keep the two\\nbattling biddies apart.\\n      \"I spotted it first, it\\'s mine,\" biddy number one screams\\nas she tries to pull the book out of biddy number two\\'s hands.\\n     \"She may have spotted it first, but I got to it before her,\"\\nyells biddy number two. She yanks the book out of the other\\nbiddy\\'s hands and tumbles backward onto the floor. \\n     \"I got it, it\\'s mine,\" she cackles with glee, clutching the\\nwar-torn book to her heaving bosom.\\n     \"Ladies, ladies,\" I manage at last.  \"There are plenty of\\ncopies for both of you.\"\\n     \"She can have that one,\" biddy number one announces,\\nstraightening her rumpled print dress.  \"I don\\'t want my John\\ndirtied by her grimy fingers.\"  With a yank to her support\\nstockings, she strolls off, oblivious to her competitor\\nwho is kissing the back cover photo of John Grisham . . . \\n     (Dusting myself off, I return to my guests)\\n     \"Now, let me see if I can think of something exciting  . . . \\nhmm . . . well, on occasion we do get to rub elbows with\\ncelebrities. Did I tell you that John Grisham graced our store\\nwith his presence?\" \\n     (There are a few oohs and aahs)\\n     \"Actually, we only saw his car . . .\"  \\n     (There are a few ohs)\\n     \"Here\\'s the story . . .\"\\n\\n\\n                          A Time To Read\\n\\n     When I came across John Grisham\\'s e-mail address in the\\nbook, \"E-Mail Addresses Of The Rich And Famous,\" I sent a letter\\nof admiration and extended an invitation to visit the store at\\nhis convenience.  I received a polite reply informing me that\\nthe person I had written to was not THE AUTHOR, John Grisham. I\\nread between the lines and realized he was telling me that he WAS\\nJohn Grisham but wanted to keep his e-mail address a secret to\\nprotect himself from fanatics, harassers, and other such\\nadmirers.  The name John Grisham was just a cover.  Clever . . . \\n     I forgot all about the letter until one day when I noticed a\\nMercedes Benz parked across the street with the license plate\\nGRISHAM.  My heart began to beat in anticipation of HIS arrival. \\nI checked the stock level of each Grisham book, hoping we\\'d have\\nenough to supply the millions of salivating fans who would line\\nthe streets for miles to obtain an autographed copy of their\\nfavorite title. I discovered that our inventory consisted of two\\ncopies of \"A Time To Kill,\" three copies of \"The Firm,\" three\\ncopies of \"The Client,\" and a whopping six copies of \"The\\nChamber.\" That should hold us for about . . . five seconds. \\nHowever, articles of clothing and body parts could be suggested\\nas alternative autographing material.\\n     Sweating profusely, knowing HE would emerge from the car at\\nany second, I debated whether I should alert the local\\nauthorities.  Mass hysteria was liable to break out once the word\\nspread of his arrival. As I was dialing the police, the Mercedes\\npulled into the street and drove off in a cloud of literary dust. \\nDisappointed, I tried to console myself with the thought that\\nperhaps his brief but memorable visit would be noted in a chapter\\nof his next book . . . \"A Time To Read.\" \\n\\n\\n     \\n     (So close yet so far, I think dreamily.  Suddenly, I realize\\nthat my guests are still here and come back down to earth) \\n     \"Well, John Grisham may not have actually been IN the store\\nbut O.J. . . .\" \\n     (My words are cut short by exclamations of \"You\\'re kidding!\"\\nand sarcastic remarks such as \"What did he buy, a book on\\nknives!\") \\n     \"EXCUSE ME!\"  \\n     (The commotion dies down) \\n     \"Thank you.\" \\n     (I continue)\\n      \"O.J. Simpson didn\\'t actually visit but a lovely lady who\\nis a very good friend of a man who was in love with O.J.\\'s\\nbrother\\'s wife did and we got to see a picture of her friend\\nholding a picture of O.J. and Nicole. I nearly fainted from the\\nthrill of it . . .\"\\n     (I pick up a copy of \"I Want To Tell You\" and brush my\\nfingers across O.J.\\'s face. Someone coughs and I replace the book\\non the shelf)   \\n     \"Many of our books deal with current events, such as the\\nO.J. Simpson trial, so it\\'s important that I keep up-to-date on\\nwhat\\'s going on in the outside world.  You may think that\\nbooksellers live in their own little world of fictitious\\ncharacters battling evil forces in faraway lands but not me, no\\nsiree.  Why, just the other day when a customer purchased a copy\\nof Barbara Bush\\'s biography, I told her what a fine job her\\nhusband was DOING as president!\" \\n     (I smile proudly) \\n     \"Here are some more examples of why \"ESPN\" is my middle\\nname . . .\"\\n\\n\\n                       While I Was Sleeping\\n\\n\\n     Customers assume that bookstore employees know the name and\\nauthor of every book that was published since the stone age. We\\nare also expected to keep up-to-date on who is writing what and\\nthe exact month, day, and minute it will be out on the shelves.\\nAnd of course, we are presumed to be in-the-know on all the\\nnonfiction titles, authors, and subjects that are hot, hip and in\\ndemand  . . . NOT!\\n     As most laboring Americans will attest, work tends to leave\\nlittle time for the real world. For me, headline news is often an\\nannouncement that there are fifty boxes to unpack rather than who\\ngot shot, flooded, or elected President. America could be seized\\nby aliens and I\\'d never know it unless one of them came in the\\nstore and bought a book.  So, sometimes you just have to fake\\nyour knowledgeability . . . \\n     \"Do you have Faye Resnick\\'s book?\" a man asked me last\\nNovember. \\n     I stood there for a moment, trying to place the name.  I\\nknew that I had heard it somewhere as it sounded very familiar.\\n     \"Is that a local author?\" I asked.  I almost crawled beneath\\na shelf when the man replied:\\n     \"She\\'s the author of the Nicole Brown Simpson book.\"\\nI vowed never to let myself be embarrassed like that again . . .  \\n     \"Do you have the book, `Sins Of The Mother\\'?\" asked a\\ncouple, two months later.\\n     I pondered the title for a second, hoping that something\\nwould click in my mind. Finally, I opened my mouth and said:\\n     \"That\\'s fiction, right?\"\\n     \"It\\'s the book by Susan Smith, the South Carolina mother who\\ndrowned her two little boys,\" the woman replied. I excused myself\\nand hid in the bathroom until they left.\\n     If I this ever happens again, I just tell everyone that I\\'ve\\nbeen conducting research on plant growth in Antarctica . . .\\n\\n\\n    (I peek my head outside the bathroom door) \\n     \"Is it safe to come out?\"\\n     (Someone nods and I emerge and pick up a stack of books) \\n     \"Well, folks, I\\'d love to gab some more but my boss wants me\\nto build a prison cell out of `The Chamber.\\'\"  I\\'ve really\\nenjoyed sharing a little of my \"book life\" with you.  Why don\\'t\\nyou come back next month and I\\'ll tell you another fascinating\\nstory or two. \\n     To remember the name of this e-zine, just think of any\\npolice officer on television and the words that he or she says as\\nthey handcuff the bad guy . . . Book \\'Em.\"\\n     \\n                         \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_book = read_file(\"C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\bookem.1\")\n",
    "file_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "U1XSbY15JRQ0"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import sys\n",
    "import re\n",
    "sys.setrecursionlimit(10000)\n",
    "file_html = read_file(\"C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\index.html\")\n",
    "soup = bs4.BeautifulSoup(file_html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qG1EbL4-RWpo"
   },
   "outputs": [],
   "source": [
    "rows = soup.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_BRrBYpTDYZ",
    "outputId": "2dd1b4fe-d04b-4f40-9c5f-0c1a12b49e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr valign=\"TOP\"><td valign=\"TOP\"><b><a href=\"FARNON\">FARNON</a></b><tab to=\"T\"><td width=\"20\"></td><td><b>The Stories of Tristan Farnon</b></td></tab></td></tr>,\n",
       " <tr valign=\"TOP\"><td valign=\"TOP\"><b><a href=\"SRE\">SRE</a></b><tab to=\"T\"><td width=\"20\"></td><td><b>The Solar Realms Elite, by Josh Renaud</b></td></tab></td></tr>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ek2F4rNZEnwk"
   },
   "outputs": [],
   "source": [
    "contents = os.walk(path)\n",
    "contents = list(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N-Tp4gLqufa8"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in contents[1:]:\n",
    "    file = open(i[0]+\"/index.html\", 'r')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    file_name = re.findall('><A HREF=\"(.*)\">', text)\n",
    "    file_title = re.findall('<BR><TD> (.*)\\n', text)\n",
    "    if file_name != []:\n",
    "        if file_name[0]== 'FARNON' :\n",
    "            file_name = file_name[2:len(file_name)]\n",
    "\n",
    "    for j in range(len(file_title)):\n",
    "          data.append((str(i[0]) + '/' + str(file_name[j]), file_title[j]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p57TWt_byuNy",
    "outputId": "2bde0b77-3882-435a-fa0f-3d440b6e7bad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories/100west.txt',\n",
       "  'Going 100 West by 53 North by Jim Prentice (1990)'),\n",
       " ('C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories/13chil.txt',\n",
       "  'The Story of the Sly Fox'),\n",
       " ('C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories/14.lws',\n",
       "  'A Smart Bomb with a Language Parser'),\n",
       " ('C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories/16.lws',\n",
       "  'Two Guys in a Garage, by M. Pshota'),\n",
       " ('C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories/17.lws',\n",
       "  'The Early Days of a High-Tech Start-up are Magic (November 18, 1991) by M. Peshota')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLBqt7prCUZ"
   },
   "source": [
    "# **Preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bTTOkn52qZi",
    "outputId": "deee9895-190a-4b02-f6e1-5727cd46d129"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nishankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nishankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJOTc4iI84wc",
    "outputId": "c5274478-083a-4928-b9c5-2b7be01bf2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in c:\\users\\nishankur\\anaconda3\\lib\\site-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\nishankur\\anaconda3\\lib\\site-packages (from num2words) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install num2words\n",
    "from num2words import num2words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nq3C7nMssqdZ"
   },
   "outputs": [],
   "source": [
    "story_doc = [read_file(name) for name,title in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7GBKBnQbwhgs"
   },
   "outputs": [],
   "source": [
    "story_title = [title for name,title in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3G1EAhCnuJoL",
    "outputId": "3c36d5da-433f-4754-cc74-fbac17f8addc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(story_doc)==len(data))\n",
    "print(len(story_doc)==len(story_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vo2aLgUm-Hbs"
   },
   "outputs": [],
   "source": [
    "#Functions for preprocessing\n",
    "punctuation = string.punctuation\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def lower_casing(data):\n",
    "      return np.char.lower(data)\n",
    "\n",
    "def remove_punct(data):\n",
    "    for i in punctuation:\n",
    "        data = np.char.replace(data, i , \" \")  \n",
    "    return data\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    valid_words = ''\n",
    "    processed_story = []\n",
    "    for story in data:\n",
    "        words = story.split()\n",
    "        for word in words:\n",
    "            if word not in stopwords.words('english'):\n",
    "                valid_words = valid_words +' '+ word\n",
    "        processed_story.append(valid_words)\n",
    "        valid_words = ''\n",
    "    return processed_story\n",
    "\n",
    "def remove_singles(data):\n",
    "    valid_words = ''\n",
    "    processed_story = []\n",
    "    for story in data:\n",
    "        words = story.split()\n",
    "        for word in words:\n",
    "            if len(word)>1:\n",
    "                valid_words = valid_words +' '+ word\n",
    "        processed_story.append(valid_words)\n",
    "        valid_words = ''\n",
    "    return processed_story\n",
    "\n",
    "def numwords(data):\n",
    "    valid_words = ''\n",
    "    processed_story = []\n",
    "    for story in data:\n",
    "        words = story.split()\n",
    "        for word in words:\n",
    "            try:\n",
    "                numword = num2words(word)\n",
    "                numword = np.char.replace(numword, \"-\", \" \")\n",
    "                valid_words = valid_words +' '+ numword\n",
    "            except:\n",
    "                valid_words = valid_words +' '+ word\n",
    "        processed_story.append(valid_words)\n",
    "        valid_words = ''\n",
    "    return processed_story\n",
    "\n",
    "def stemwords(data):\n",
    "    valid_words = ''\n",
    "    processed_story = []\n",
    "    for story in data:\n",
    "        words = story.split()\n",
    "        for word in words:\n",
    "            word = stemmer.stem(word)\n",
    "            valid_words = valid_words +' '+ word\n",
    "        processed_story.append(valid_words)\n",
    "        valid_words = ''\n",
    "    return processed_story\n",
    "  \n",
    "def preprocessor(data):\n",
    "    data = lower_casing(data)\n",
    "    data = remove_punct(data)\n",
    "    data = numwords(data)\n",
    "    data = remove_stopwords(data)\n",
    "    data = remove_singles(data)\n",
    "    data = stemwords(data)\n",
    "    data = remove_singles(data)\n",
    "    data = numwords(data)\n",
    "    data = remove_stopwords(data)\n",
    "  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Y1n4eeZ24qQO"
   },
   "outputs": [],
   "source": [
    "processed_title = preprocessor(story_title)\n",
    "processed_title_tokens = [word_tokenize(title) for title in processed_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0MFUl8LJ8pnz"
   },
   "outputs": [],
   "source": [
    "processed_story = preprocessor(story_doc)\n",
    "processed_story_tokens = [word_tokenize(story) for story in processed_story]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UqiI1tJ5gBC0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_story) == len(processed_title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MLc_F-gAoB6F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(processed_story)\n",
    "len(processed_story_tokens) == len(processed_title_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qu9O0WU52hZ8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sharewar',\n",
       " 'trial',\n",
       " 'project',\n",
       " 'freewar',\n",
       " 'need',\n",
       " 'support',\n",
       " 'continu',\n",
       " '100',\n",
       " 'west',\n",
       " '53']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_story_tokens[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ug3nyHdptHjA"
   },
   "outputs": [],
   "source": [
    "DF = {}\n",
    "for i in range(N):\n",
    "    for w in processed_story_tokens[i]:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "    for w in processed_title_tokens[i]:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mZBfJW08oftW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharewar : 5\n",
      "trial : 35\n",
      "project : 63\n",
      "freewar : 1\n",
      "need : 243\n",
      "support : 87\n",
      "continu : 193\n",
      "100 : 38\n",
      "west : 65\n",
      "53 : 12\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for key ,value in DF.items():\n",
    "    DF[key] = len(DF[key])\n",
    "\n",
    "for key ,value in DF.items():\n",
    "    c += 1\n",
    "    print(f\"{key} : {value}\")\n",
    "    if c==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "peTNVD5I5N-N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33221"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_unique_words = list(DF.keys())\n",
    "len(total_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AZ6xRbq_8eMY"
   },
   "outputs": [],
   "source": [
    "#tf-idf for body\n",
    "tf_idf_body = {}\n",
    "for i in range(N):\n",
    "    tokens = processed_story_tokens[i]\n",
    "    title = processed_title_tokens[i]\n",
    "    counter = Counter(title + tokens)\n",
    "    n = len(tokens+title)\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/n\n",
    "        try:\n",
    "            df = DF[token]/N\n",
    "        except:\n",
    "            df = 0\n",
    "        idf = np.log(N/(df+1))\n",
    "        tf_idf_body[i, token] = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kD9wU-pI8ny1"
   },
   "outputs": [],
   "source": [
    "#tf-idf for title\n",
    "tf_idf_title = {}\n",
    "for i in range(N):\n",
    "    tokens = processed_title_tokens[i]\n",
    "    body = processed_story_tokens[i]\n",
    "    counter = Counter(body + tokens)\n",
    "    n = len(tokens+body)\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/n\n",
    "        try:\n",
    "            df = DF[token]/N\n",
    "        except:\n",
    "            df = 0\n",
    "        idf = np.log(N/(df+1))\n",
    "        tf_idf_title[i, token] = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vh6BeN5dNLqV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341714"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NyR9IUMt2THR"
   },
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "for key ,value in tf_idf_body.items():\n",
    "    tf_idf_body[key] = value*alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Uk_yaQTb4Q3G"
   },
   "outputs": [],
   "source": [
    "for key ,value in tf_idf_title.items():\n",
    "    tf_idf_body[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aXcNkliI5uek"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342003"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3RoJ92ExN4RG"
   },
   "outputs": [],
   "source": [
    "tf_idf = tf_idf_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfrB4J34NifT"
   },
   "source": [
    "#**Matching Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kcaBOVgmNhtK"
   },
   "outputs": [],
   "source": [
    "def matches(text):\n",
    "    query_score = {}\n",
    "    text = [text]\n",
    "    processed_text = preprocessor(text)\n",
    "    processed_tokens = word_tokenize(processed_text[0])\n",
    "    for key in tf_idf:\n",
    "        if key[1] in processed_tokens:\n",
    "            try:\n",
    "                query_score[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_score[key[0]] = tf_idf[key]\n",
    "    query_score = sorted(query_score.items(),key = lambda x:x[1],reverse=True)\n",
    "    return query_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Tui_-lC041y3"
   },
   "outputs": [],
   "source": [
    "query1 = \"Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "heNqS0xSVSt1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches1 = matches(query1)\n",
    "len(all_matches1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "p0kVYnK2ZLkq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten matches:\n",
      "C:\\Users\\Nishankur\\text_files\\stories/fea3\n",
      "C:\\Users\\Nishankur\\text_files\\stories/ghost\n",
      "C:\\Users\\Nishankur\\text_files\\stories/quarter.c6\n",
      "C:\\Users\\Nishankur\\text_files\\stories/quarter.c4\n",
      "C:\\Users\\Nishankur\\text_files\\stories/foxnstrk.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/quarter.c15\n",
      "C:\\Users\\Nishankur\\text_files\\stories/narciss.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/foxngrap.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/vday.hum\n",
      "C:\\Users\\Nishankur\\text_files\\stories/quarter.c9\n"
     ]
    }
   ],
   "source": [
    "def file_name(all_matches):\n",
    "    print(\"Top ten matches:\")\n",
    "    for i in range(10):\n",
    "        value = all_matches[i][0]\n",
    "        print(data[value][0])\n",
    "\n",
    "file_name(all_matches1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "h-S14C0iadIo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE ROSE\\nby Suzy Edmonson\\n\\n     \"How beautiful!  A rose!\"\\n     She quickly filled a vase with water and set the vase on the living room\\ntable.  She sat for several minutes gazing at the beauty of the delicate\\nblossom.  Then the phone rang and the rose was forgotten.  The next day, she\\nstopped to admire the perfection of the flower but then ran out the door heading\\nfor school.  When the girl arrived home that night, she filled the vase with\\nfresh water and deeply inhaled the rose\\'s flowery scent.  Then she retreated to\\nher room to begin her homework.  She woke up late the next morning and ran out\\nthe door with only a quick glance at the rose.  Night came and the girl didn\\'t\\ncome home.  At one o\\'clock the girl tiptoed into the house, ran into her room\\nand fell asleep on her bed.  For the rest of the week the girl went about her\\ndaily routines forgetting the rose on the table.  It was not so beautiful\\nanymore.  The stem sagged, the blossom had lost its vibrant color and the once\\nlively petals now hung limply from the stem.  One night the girl arrived home\\nlater then usual.  As she passed by the lonely rose, it straightened on its\\ntired stem and rearranged its petals to perfection.  A glow seemed to radiate\\nfrom within the rose.  The girl continued walking to her room and the rose was\\nleft unnoticed.  As she turned off the light in the living room, the rose\\ndropped a single petal.  Like a teardrop it fell silently to the floor where it\\nlay motionless.  Then the once beautiful rose shriveled and was no more.\\n\\n\\n\\n\\n\\x1a'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file(\"C:\\\\Users\\\\Nishankur\\\\text_files\\\\stories\\\\quarter.c9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6BFI3S2-ViA"
   },
   "source": [
    "#**Document Vector creation and macthing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "l64-g7adxtmL"
   },
   "outputs": [],
   "source": [
    "#document vectors\n",
    "doc_vec = np.zeros((N,len(total_unique_words)))\n",
    "for (doc,word),value in tf_idf.items():\n",
    "    try:\n",
    "        i = total_unique_words.index(word)\n",
    "        doc_vec[doc][i]= value\n",
    "    except:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "G9ofsdINAhnC"
   },
   "outputs": [],
   "source": [
    "#Query vector\n",
    "def query_vectorizer(text):\n",
    "    query_vec = np.zeros(len(total_unique_words))\n",
    "    text = [text]\n",
    "    processed_text = preprocessor(text)\n",
    "    processed_tokens = word_tokenize(processed_text[0])\n",
    "    counter = Counter(processed_tokens)\n",
    "    tot_words = len(processed_tokens)\n",
    "    for word in processed_tokens:\n",
    "        tf = counter[word]/tot_words\n",
    "        try:\n",
    "            df = DF[word]/N\n",
    "        except:\n",
    "            df = 0\n",
    "        idf = np.log(N/(df+1))\n",
    "        try:\n",
    "            i = total_unique_words.index(word)\n",
    "            query_vec[i]= tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33221"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_vectorizer(query1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity calculator\n",
    "def cosine_sim(a,norm_a,doc):\n",
    "    b = doc\n",
    "    cos_sim = np.dot(a, b)/(norm_a*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_20(query):\n",
    "    query_vec = query_vectorizer(query)\n",
    "    norm_a = np.linalg.norm(query_vec)\n",
    "    query_score = {}\n",
    "    n_doc = len(doc_vec)\n",
    "    for i in range(n_doc):\n",
    "        query_score[i] = cosine_sim(query_vec,norm_a,doc_vec[i]) \n",
    "    query_score = sorted(query_score.items(),key = lambda x:x[1],reverse=True)\n",
    "    return query_score[:20]\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = 'To make matters worse, up raced a large dog, snarling viciously. The fox \\ndropped the hen and tried to jump out of the hen run. At the first try, he \\nfell back, perhaps weak with fright. He could almost feel the dog\\'s fangs sink\\ninto his ear, but with a desperate jump, he got over the fence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches2 = top_20(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten matches:\n",
      "C:\\Users\\Nishankur\\text_files\\stories/foxngrap.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/greedog.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/korea.s\n",
      "C:\\Users\\Nishankur\\text_files\\stories/aesopa10.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/friends.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/fran\n",
      "C:\\Users\\Nishankur\\text_files\\stories/running.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/foxnstrk.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/friend.s\n",
      "C:\\Users\\Nishankur\\text_files\\stories/13chil.txt\n"
     ]
    }
   ],
   "source": [
    "file_name(all_matches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"hen she retreated to\\nher room to begin her homework.  She woke up late the next morning and ran out\\nthe door with only a quick glance at the rose.  Night came and the girl didn\\'t\\ncome home.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches3 = top_20(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten matches:\n",
      "C:\\Users\\Nishankur\\text_files\\stories/quarter.c9\n",
      "C:\\Users\\Nishankur\\text_files\\stories/girlclub.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/lpeargrl.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/roger1.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/running.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/enginer.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/bulmrx.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/girl\n",
      "C:\\Users\\Nishankur\\text_files\\stories/3student.txt\n",
      "C:\\Users\\Nishankur\\text_files\\stories/wlgirl.txt\n"
     ]
    }
   ],
   "source": [
    "file_name(all_matches3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
